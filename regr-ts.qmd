
# Regresión con series temporales

{{< include _macros.qmd >}}

## Selección del número de retardos

### Introducción

-   Modelo ARDL($p$, $q$):
    $$
       y_t = \alpha + \rho_1 y_{t-1} + \dots + \rho_p y_{t-p} +
       \beta_0 z_t + \beta_1 z_{t-1} + \dots + \beta_q z_{t-q} +
       u_t
    $$

-   ¿Cuántos retardos hay que incluir en una regresión de series
    temporales?

-   ¿Qué métodos podemos usar para determinar el número de retardos?

### Selección de retardos

-   Si se selecciona un número demasiado pequeño de retardos se omite
    información relevante.

-   Con un número demasiado grande se pierde eficiencia.

### Selección de modelos

-   Se establece un número máximo de retardos a considerar procurando
    que sea lo suficientemente elevado para capturar todas las
    relaciones dinámicas.

-   Se estiman modelos de regresión con diferente número de retardos.
    **La muestra debe ser la misma en todas las regresiones**.

-   Se utiliza algún indicador para determinar cuál es el modelo más
    adecuado.

### Contrastes F

-   Se contrasta la significación del último retardo usando un
    contraste $F$. Si el último retardo no es significativo, se estima
    un nuevo modelo sin ese retardo y se vuelve a repetir el proceso.

-   Los contrastes $F$ no están diseñados para seleccionar modelos y el
    procedimiento tiende a seleccionar más retardos de los necesarios.

### Criterios de información

-   En la selección de modelos se suele usar algún **criterio de
    información**: medidas de la bondad del ajuste que incluyen una
    penalización creciente en el número de parámetros.

-   Se estiman todos los modelos con diferente número de retardos que se
    quieran comparar. Se selecciona aquel con un menor valor del
    criterio de información.

### Algunos criterios de información

-   **AIC**: criterio de información de Akaike. En los modelos de
    regresión puede escribirse como:
    $$
       \text{AIC} = C + T \log\left(\frac{\SCR}{T}\right) + 2 (K + 1),
    $$
    donde $C$ es una constante, $T$ es el número de observaciones,
    $\SCR$ es la suma del cuadrado de los residuos y $K$ es el número de
    parámetros.

-   **BIC**: criterio de información bayesiano.
    $$
       \text{BIC} = C + T \log\left(\frac{\SCR}{T}\right) + \log(T) (K + 1).
    $$
    Se diferencia del AIC en que penaliza más el número de parámetros.

### Comparación entre criterios

-   Usando el BIC se obtiene una estimación consistente del número de
    retardos.

-   El AIC produce resultados similares aunque suele seleccionar un
    número de retardos mayor que el BIC.

## Regresión espuria

### Regresión espuria en cortes transversales

-   Dos variables, $y$ y $x$, parecen estar muy correlacionadas y la
    regresión de $y$ sobre $x$ produce resultados significativos.

-   La relación entre $y$ y $x$ desaparece cuando se incluye una tercera
    variable, $z$, en la regresión.

-   La regresión de $y$ sobre $x$ es un ejemplo de **regresión
    espuria**.

### Regresión espuria en series temporales

-   La omisión de variables relevantes también puede producir
    regresiones espurias con datos de series temporales.

-   Además, es muy frecuente encontrar regresiones espurias cuando se
    incluyen series temporales con tendencia o que sean altamente
    persistentes.

### Tipos de tendencia

La **tendencia** de una serie temporal está constituida por movimientos
persistentes a largo plazo. Distinguimos entre:

-   Tendecias deterministas.

-   Tendencias estocásticas.

### Tendencias deterministas

-   Una **tendencia determinista** es una función no aleatoria del
    tiempo.

-   Por ejemplo, si $y_t$ fluctúa alrededor de una **tendencia lineal**:
    $$
      y_t = \alpha + \delta t + u_t,
    $$
    donde $u_t$ es un proceso estacionario y débilmente dependiente.

### Regresión y tendencias lineales

-   Regresión con dos variables, $y_t$ y $x_t$, las cuales no están
    relacionadas pero presentan **tendencias lineales**:
    $$
      y_t = \alpha + \beta x_t + u_t.
    $$

-   A pesar de que $\beta = 0$, la regresión anterior con frecuencia
    indicaría que existe una relación significativa entre las dos
    variables.

-   Para evitar encontrar regresiones espurias, es aconsejable
    introducir una tendencia lineal en la regresión anterior:
    $$
      y_t = \alpha + \beta x_t + \delta t + u_t.
    $$

### Tendencias estocásticas

-   Una **tendencia estocástica** es aleatoria y varía con el paso del
    tiempo.

-   El ejemplo más simple de una variable con tendencia estocástica es
    el **paseo aleatorio**:
    $$
      y_t = y_{t-1} + e_t.
    $$

-   Un paseo aleatorio alterna episodios de crecimiento durante varios
    periodos, con episodios donde la tendencia es decreciente.

### Paseo aleatorio con deriva

-   Algunas series tienen una tendencia de crecimiento sostenido a largo
    plazo.

-   **Paseo aleatorio con deriva**:
    $$
      y_t = \delta + y_{t-1} + e_t.
    $$

-   Si el parámetro $\delta > 0$ la variable $y_t$ tiende a crecer con
    el paso del tiempo.

### Raíces unitarias

-   Un paseo aleatorio es un caso especial de un AR(1), donde
    $\rho = 1$, incumpliendo la condición de estabilidad.

-   La condición de estabilidad de procesos AR(*p*) es más complicada y depende del valor de las raíces del **polinomio característico**: un polinomio de orden $p$ formado a partir de los coeficientes del proceso AR(*p*).

-   Cuando una de esas raíces sea igual a 1, se dice que el proceso
    tiene una **raíz unitaria**.

### Raíces unitarias, tendencias estocásticas y procesos I(1)

-   Si un proceso tiene una raíz unitaria entonces tiene una tendencia
    estocástica.

-   La diferencia de un proceso con una raíz unitaria no tiene tendencia
    estocástica.

-   Un proceso con una raíz unitaria es un proceso integrado de orden 1,
    I(1).

### Regresión espuria y tendencias estocásticas

-   Si $y_t$ y $x_t$ son procesos I(1), la regresión de $y_t$ sobre
    $x_t$ mostrará con mucha frecuencia resultados muy significativos
    aunque, en realidad, las dos variables no estén relacionadas.

-   Cuando $y_t$ y $x_t$ están relacionadas y tienen una tendencia
    común, los residuos de la regresión de $y_t$ sobre $x_t$ deberían
    comportarse como un proceso I(0). En ese caso las variables están
    **cointegradas**.

### Regresión con variables con tendencias

-   Debemos añadir un término de tendencia lineal cuando alguna de las
    variables presente tendencias deterministas.

-   Las variables con raíz unitaria deben ser diferenciadas para
    eliminar las tendencias estocásticas.

-   La posibilidad de que haya relaciones de cointegración entre
    variables I(1) no se explorará en este curso.

## Contrastes de raíz unitaria

### Modelo AR(1)

El modelo autorregresivo de orden 1, AR(1), puede escribirse
como:
$$
  y_t = \alpha + \rho y_{t-1} + u_t,
$$
donde $u_t$ es un ruido blanco.

### Estacionariedad y dependencia débil

Las propiedades dinámicas del proceso AR(1) dependen del
valor de $\rho$:

-   $y_t$ es estacionario y débilmente dependiente si $\abs{\rho} < 1$.

-   $y_t$ es un paseo aleatorio si $\rho = 1$.

-   $y_t$ tiene un comportamiento explosivo cuando $\rho > 1$.

### Detección de raíces unitarias

-   Los estadísticos habituales no pueden usarse para contrastar la
    existencia de una raíz unitaria.

-   La estimación MCO del parámetro $\rho$ está sesgada hacia abajo y el
    sesgo aumenta cuanto más cerca está $\rho$ de 1.

-   La distribución del estadístico $t = (\hat{\rho} - 1)/\se({\rho})$
    es muy diferente de una $t_{T-2}$ o de una normal cuando $\rho$
    tiene un valor cercano a 1.

### Regresión de Dickey-Fuller

-   Proceso AR(1):
    $$
      y_t = \alpha + \rho y_{t-1} + u_t,
    $$

-   Restando $y_{t-1}$ de ambos lados:
    $$
      \incr y_t = \alpha + (\rho - 1) y_{t-1} + u_t.
    $$

-   Dickey y Fuller plantean contrastar la existencia de una raíz
    unitaria estimado por MCO el modelo de regresión:
    $$
      \incr y_t = \alpha + \beta y_{t-1} + u_t.
    $$

### Contraste $\bm{t}$ de Dickey-Fuller

-   Regresión de Dickey y Fuller:
    $$
      \incr y_t = \alpha + \beta y_{t-1} + u_t.
    $$

-   La existencia de una raíz unitaria implica que $\beta = 0$.

-   Dickey y Fuller proponen contrastar la hipótesis nula
    $H_0\!: \beta = 0$ frente a la alternativa $H_1\!: \beta < 0$ mediante un contraste
    $t$ de una cola.

### Distribución del contraste de Dickey-Fuller

-   **No debe usarse un contraste $\bm{t}$ robusto a
    heteroscedasticidad**. Bajo la hipótesis nula el contraste $t$
    tradicional es válido aunque haya heteroscedasticidad.

-   El contraste de Dickey-Fuller bajo la hipótesis nula no sigue una
    distribución normal ni ninguna otra distribución convencional.

-   Los valores críticos del contraste se obtienen mediante simulación:

    +-----------+-----------+-----------+
    | $10\%$    | $5\%$     | $1\%$     |
    +==========:+==========:+==========:+
    | $-2{,}57$ | $-2{,}86$ | $-3{,}43$ |
    +-----------+-----------+-----------+

### Contraste de Dickey-Fuller aumentado

-   Si $y_t$ sigue un proceso AR(*p*) es necesario incluir
    $p-1$ retardos de $\incr y_t$ en la regresión de Dickey-Fuller para
    obtener un contraste válido:
    $$
      \incr y_t =
      \alpha + \beta y_{t-1} + \phi_1 \incr y_{t-1}  +
      \phi_2 \incr y_{t-2} + \dots  + \phi_{p-1} \incr y_{t-p+1}  + u_t.
    $$

-   Los valores críticos de Dickey-Fuller son válidos para contrastar
    $H_0\!: \beta = 0$ frente a $H_1\!: \beta < 0$.

### Selección de retardos

-   Es conveniente utilizar un criterio de información para seleccionar
    el número de retardos a incluir en la regresión de Dickey-Fuller.

-   Para el constraste de Dickey-Fuller aumentado es preferible el AIC.

### Tendencias

-   Si $y_t$ presenta una tendencia creciente o decreciente es
    aconsejable añadir una tendencia lineal a la regresión de
    Dickey-Fuller:
    $$
      \incr y_t =
      \alpha + \delta t + \beta y_{t-1} + \phi_1 \incr y_{t-1}  +
      \phi_2 \incr y_{t-2} + \dots  + \phi_{p-1} \incr y_{t-p+1}  + u_t.
    $$

-   Cuando se incluye una tendencia, la distribución del contraste de
    Dickey-Fuller es diferente y es necesario usar otros valores
    críticos:

    +-----------+-----------+-----------+
    | $10\%$    | $5\%$     | $1\%$     |
    +==========:+==========:+==========:+
    | $-3{,}12$ | $-3{,}41$ | $-3{,}96$ |
    +-----------+-----------+-----------+


### Resumen

-   Mediante la inspección de gráficos, se determina si es necesario
    incluir una tendencia lineal en la regresión de Dickey-Fuller.

-   Se selecciona el número de retardos en la regresión de Dickey-Fuller
    de acuerdo con el valor del AIC.

-   Se rechaza la presencia de raíz unitaria cuando el valor del
    cociente $t$ para $H_0\!: \beta = 0$ frente a $H_1\!: \beta < 0$ es
    menor que los valores críticos de la siguiente tabla:

    +------------------+-----------+-----------+-----------+
    | Tendencia lineal | $10\%$    | $5\%$     | $1\%$     |
    +:=================+==========:+==========:+==========:+
    | No               | $-2{,}57$ | $-2{,}86$ | $-3{,}43$ |
    +------------------+-----------+-----------+-----------+
    | Sí               | $-3{,}12$ | $-3{,}41$ | $-3{,}96$ |
    +------------------+-----------+-----------+-----------+


## Otras cuestiones

### Multiplicadores de largo plazo (I)

-   Modelo con tres retardos de la variable explicativa:
    $$
       y_t = \alpha + \beta_0 z_t + \beta_1 z_{t-1} + \beta_2 z_{t-2} + \beta_3 z_{t-3} + u_t.
    $$

-   Es posible reescribir el modelo anterior como:
    $$
       y_t = \alpha + \delta_0 \incr z_t + \delta_1 \incr z_{t-1} +
       \delta_2 \incr z_{t-2} + \delta_3 z_{t-3} + u_t
    $$

-   Con la regresión anterior se estiman directamente los
    multiplicadores acumulativos y de largo plazo y sus correspondientes
    errores típicos.

### Multiplicadores de largo plazo (y II)

-   Modelo ARDL($p$, $q$):
    $$
       y_t = \alpha + \rho_1 y_{t-1} + \dots + \rho_p y_{t-p} +
       \beta_0 z_t + \beta_1 z_{t-1} + \dots + \beta_q z_{t-q} +
       u_t
    $$

-   El multiplicador de largo plazo es una función no lineal de los
    parámetros:
    $$
       \delta_{\text{LP}} = \frac{\sum_{j=0}^q \beta_j}{1 - \sum_{j=1}^p \rho_j}.
    $$

-   En este curso no se tratará como obtener los multiplicadores
    acumulativos y sus errores típicos en modelos ARDL.

### Cambio estructural

-   Se produce un **cambio estructural** cuando los parámetros del
    modelo de regresión no permanecen constantes a lo largo de todo el
    periodo muestral.

-   Consideraremos el caso de que los parámetros sólo cambian una vez y
    que conocemos en qué periodo se produce el cambio.

### Contraste de Chow (I)

-   Modelo de regresión original:
    $$
      y_t = \beta_0 + \beta_1 x_{1t}  + \beta_2 x_{2t} + u_t.
    $$

-   El **contraste de Chow** puede usarse cuando se sospecha de la
    existencia de un cambio estructural en el periodo $\tau$, $1 < \tau
     < T$.

-   Creamos una variable ficticia $D_t$ que toma el valor 0 en todos los
    periodos anteriores a $\tau$ y valor 1 a partir del periodo $\tau$.
    $$
      D_t =
      \begin{cases}
        0 & \text{si $t < \tau$}, \\
        1 & \text{si $t \geq \tau$}.
      \end{cases}
    $$

### Contraste de Chow (y II)

-   Añadimos al modelo original la variable $D_t$ así como interacciones
    de $D_t$ con todas las variables explicativas:
    $$
      y_t = \beta_0 + \beta_1 x_{1t}  + \beta_2 x_{2t} +
      \theta_0 D_t + \theta_1 D_t x_{1t}   + \theta_2 D_t x_{2t}
      + u_t.
    $$

-   Bajo la hipótesis nula de que no se ha producido cambio estructural,
    los términos que se han añadido no son significativos.

-   Puede usarse un estadístico $F$ para contrastar $\theta_0 = \theta_1
     = \theta_2 = 0$.

-   En caso que se rechace la hipótesis nula, el parámetro $\theta_j$
    muestra como ha cambiado el parámetro $\beta_j$ a partir del periodo
    $\tau$.

### Estacionalidad

-   Con datos trimestrales y mensuales es usual observar variables con
    fuertes oscilaciones estacionales.

-   Una forma simple de controlar este tipo de variación es incluir
    **variables ficticias estacionales** en el modelo de regresión.

### Variables ficticias estacionales

-   Con datos trimestrales podemos definir cuatro variables ficticias
    estacionales $D^s_t$, $s = 1, \dots, 4$:
    $$
      D^s_t =
      \begin{cases}
        0 & \text{si $t$ corresponde al trimestre $s$}, \\
        1 & \text{en caso contrario}.
      \end{cases}
    $$

-   En la regresión sólo incluiríamos tres de estas variables. De otra
    forma, incurriríamos en la **trampa de la variables ficticias**.

-   De la misma manera, para controlar la estacionalidad en datos
    mensuales incluiríamos un conjunto de 11 variables ficticias
    estacionales.
